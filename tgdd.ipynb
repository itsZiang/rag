{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2270d206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Found 123 products on page 1\n",
      "Valid products processed: 40/123\n",
      "Current total unique products: 40\n",
      "Scraping page 2...\n",
      "Found 181 products on page 2\n",
      "Valid products processed: 60/181\n",
      "Current total unique products: 60\n",
      "Scraping page 3...\n",
      "Found 227 products on page 3\n",
      "Valid products processed: 79/227\n",
      "Current total unique products: 79\n",
      "Scraping page 4...\n",
      "Found 253 products on page 4\n",
      "Valid products processed: 99/253\n",
      "Current total unique products: 99\n",
      "Scraping page 5...\n",
      "Found 291 products on page 5\n",
      "Valid products processed: 119/291\n",
      "Current total unique products: 119\n",
      "Scraping page 6...\n",
      "Found 309 products on page 6\n",
      "Valid products processed: 131/309\n",
      "Current total unique products: 131\n",
      "Scraping page 7...\n",
      "Found 309 products on page 7\n",
      "Valid products processed: 131/309\n",
      "Current total unique products: 131\n",
      "No new products found on page 7. Total count remained at 131. Stopping...\n",
      "Finished scraping at page 6\n",
      "Collected 131 unique products\n",
      "\n",
      "First 5 products:\n",
      "1. OPPO Reno14 F 5G 12GB/256GB\n",
      "   URL: https://www.thegioididong.com/dtdd/oppo-reno14-f-5g-12gb-256gb\n",
      "\n",
      "2. Samsung Galaxy Z Flip7 FE 5G 8GB/128GB\n",
      "   URL: https://www.thegioididong.com/dtdd/samsung-galaxy-z-flip7-fe\n",
      "\n",
      "3. iPhone 16 Pro Max 256GB\n",
      "   URL: https://www.thegioididong.com/dtdd/iphone-16-pro-max\n",
      "\n",
      "4. iPhone 16 Pro 128GB\n",
      "   URL: https://www.thegioididong.com/dtdd/iphone-16-pro\n",
      "\n",
      "5. Samsung Galaxy Z Fold7 5G 12GB/256GB\n",
      "   URL: https://www.thegioididong.com/dtdd/samsung-galaxy-z-fold7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "BASE_URL   = \"https://www.thegioididong.com/dtdd#c=42&o=13&pi={}\"\n",
    "TIMEOUT    = 15\n",
    "MAX_PAGES  = 50  # Gi·ªõi h·∫°n t·ªëi ƒëa ƒë·ªÉ tr√°nh infinite loop\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "def scroll_to_bottom(driver):\n",
    "    \"\"\"Scroll t·ª´ t·ª´ ƒë·ªÉ load h·∫øt s·∫£n ph·∫©m\"\"\"\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # TƒÉng th·ªùi gian ch·ªù\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "all_links = []\n",
    "\n",
    "def detect_last_page(driver):\n",
    "    \"\"\"Detect xem c√≥ ph·∫£i trang cu·ªëi kh√¥ng\"\"\"\n",
    "    try:\n",
    "        # Ki·ªÉm tra kh√¥ng c√≥ s·∫£n ph·∫©m n√†o\n",
    "        products = driver.find_elements(By.CSS_SELECTOR, \"ul.listproduct li\")\n",
    "        if len(products) == 0:\n",
    "            return True\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "all_links = []\n",
    "page = 1\n",
    "previous_total_count = 0\n",
    "\n",
    "while page <= MAX_PAGES:\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    \n",
    "    # ƒêi·ªÅu h∆∞·ªõng ƒë·∫øn trang\n",
    "    driver.get(BASE_URL.format(page))\n",
    "    \n",
    "    # Ch·ªù trang load xong\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # REFRESH/RELOAD trang nh∆∞ b·∫•m Ctrl + R\n",
    "    driver.refresh()\n",
    "    \n",
    "    # Ch·ªù sau khi refresh\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        # Scroll ƒë·ªÉ load h·∫øt s·∫£n ph·∫©m\n",
    "        scroll_to_bottom(driver)\n",
    "        \n",
    "        # Ch·ªù elements xu·∫•t hi·ªán\n",
    "        wait = WebDriverWait(driver, TIMEOUT)\n",
    "        wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"ul.listproduct li\")))\n",
    "        \n",
    "        # T√¨m t·∫•t c·∫£ s·∫£n ph·∫©m\n",
    "        lis = driver.find_elements(By.CSS_SELECTOR, \"ul.listproduct li\")\n",
    "        print(f\"Found {len(lis)} products on page {page}\")\n",
    "        \n",
    "        # N·∫øu kh√¥ng c√≥ s·∫£n ph·∫©m n√†o, d·ª´ng l·∫°i\n",
    "        if len(lis) == 0:\n",
    "            print(f\"No products found on page {page}. Stopping...\")\n",
    "            break\n",
    "        \n",
    "        # Th√™m s·∫£n ph·∫©m v√†o danh s√°ch\n",
    "        valid_products = 0\n",
    "        for i, li in enumerate(lis, 1):\n",
    "            try:\n",
    "                # Th·ª≠ nhi·ªÅu selector kh√°c nhau cho link\n",
    "                a = None\n",
    "                for selector in [\"a\", \"a[href]\", \".product-link\", \"[href]\"]:\n",
    "                    a_elements = li.find_elements(By.CSS_SELECTOR, selector)\n",
    "                    if a_elements:\n",
    "                        a = a_elements[0]\n",
    "                        break\n",
    "                \n",
    "                if not a:\n",
    "                    continue\n",
    "                \n",
    "                # Th·ª≠ nhi·ªÅu selector kh√°c nhau cho title\n",
    "                h3 = None\n",
    "                title = \"\"\n",
    "                for selector in [\"h3\", \".product-title\", \".title\", \"h3 a\", \"a\"]:\n",
    "                    h3_elements = li.find_elements(By.CSS_SELECTOR, selector)\n",
    "                    if h3_elements:\n",
    "                        h3 = h3_elements[0]\n",
    "                        title = h3.text.strip()\n",
    "                        if title:\n",
    "                            break\n",
    "                \n",
    "                if not title:\n",
    "                    continue\n",
    "                \n",
    "                href = a.get_attribute(\"href\")\n",
    "                \n",
    "                if href and title:\n",
    "                    all_links.append({\"href\": href, \"title\": title})\n",
    "                    valid_products += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                # Ch·ªâ log l·ªói n·∫øu debug mode\n",
    "                # print(f\"Skipping product {i}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"Valid products processed: {valid_products}/{len(lis)}\")\n",
    "        \n",
    "        # L·ªçc tr√πng l·∫∑p t·∫°m th·ªùi ƒë·ªÉ ƒë·∫øm ch√≠nh x√°c\n",
    "        unique_links_temp = []\n",
    "        seen = set()\n",
    "        for link in all_links:\n",
    "            key = (link[\"href\"], link[\"title\"])\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                unique_links_temp.append(link)\n",
    "        \n",
    "        current_total_count = len(unique_links_temp)\n",
    "        print(f\"Current total unique products: {current_total_count}\")\n",
    "        \n",
    "        # KI·ªÇM TRA: N·∫øu s·ªë l∆∞·ª£ng kh√¥ng tƒÉng l√™n, d·ª´ng l·∫°i\n",
    "        if current_total_count == previous_total_count:\n",
    "            print(f\"No new products found on page {page}. Total count remained at {current_total_count}. Stopping...\")\n",
    "            break\n",
    "        \n",
    "        # C·∫≠p nh·∫≠t count cho l·∫ßn ki·ªÉm tra ti·∫øp theo\n",
    "        previous_total_count = current_total_count\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error on page {page}: {e}\")\n",
    "        break\n",
    "    \n",
    "    # Ngh·ªâ gi·ªØa c√°c page ƒë·ªÉ tr√°nh b·ªã block\n",
    "    time.sleep(2)\n",
    "    page += 1\n",
    "\n",
    "print(f\"Finished scraping at page {page - 1}\")\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# L·ªçc tr√πng l·∫∑p\n",
    "unique_links = []\n",
    "seen = set()\n",
    "\n",
    "for link in all_links:\n",
    "    key = (link[\"href\"], link[\"title\"])\n",
    "    if key not in seen:\n",
    "        seen.add(key)\n",
    "        unique_links.append(link)\n",
    "\n",
    "print(f\"Collected {len(unique_links)} unique products\")\n",
    "print(\"\\nFirst 5 products:\")\n",
    "for i, link in enumerate(unique_links[:5], 1):\n",
    "    print(f\"{i}. {link['title']}\")\n",
    "    print(f\"   URL: {link['href']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "502d7e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eb5815",
   "metadata": {},
   "source": [
    "loop qua m·ªói `unique_links`, l·∫•y nh·ªØng th√¥ng s·ªë c·∫ßn thi·∫øt nh∆∞ m√†n h√¨nh, pin, camera,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# ‚úÖ Chuy·ªÉn h·∫øt v·ªÅ lowercase ƒë·ªÉ so kh·ªõp\n",
    "ALLOWED_KEYS = {\n",
    "    \"c√¥ng ngh·ªá m√†n h√¨nh\",\n",
    "    \"ƒë·ªô ph√¢n gi·∫£i m√†n h√¨nh\",\n",
    "    \"m√†n h√¨nh r·ªông\",\n",
    "    \"h·ªá ƒëi·ªÅu h√†nh\",\n",
    "    \"ƒë·ªô ph√¢n gi·∫£i camera sau\",\n",
    "    \"ƒë·ªô ph√¢n gi·∫£i camera tr∆∞·ªõc\",\n",
    "    \"chip x·ª≠ l√Ω (cpu)\",\n",
    "    \"ram\",\n",
    "    \"dung l∆∞·ª£ng l∆∞u tr·ªØ\",\n",
    "    \"sim\",\n",
    "    \"m·∫°ng di ƒë·ªông\",\n",
    "    \"dung l∆∞·ª£ng pin\",\n",
    "    \"h·ªó tr·ª£ s·∫°c t·ªëi ƒëa\",\n",
    "    \"h√£ng\"\n",
    "}\n",
    "\n",
    "product_details = []\n",
    "\n",
    "for i, link in enumerate(unique_links, 1):\n",
    "    url = link[\"href\"]\n",
    "    title = link[\"title\"]\n",
    "    print(f\"({i}/{len(unique_links)}) Crawling details for: {title}\")\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, timeout=10)\n",
    "        r.encoding = \"utf-8\"  # ‚úÖ S·ª≠a l·ªói encoding\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "        specs = {}\n",
    "\n",
    "        # ‚úÖ Lo·∫°i 1 (ch·ªâ l∆∞u l·∫°i c√°c key ƒë∆∞·ª£c ph√©p)\n",
    "        items = soup.select(\"div.item.cf-right ul.parameter li\")\n",
    "        if items:\n",
    "            for li in items:\n",
    "                span = li.find(\"span\")\n",
    "                div = li.find(\"div\")\n",
    "                if span and div:\n",
    "                    key = span.text.strip().lower().replace(\":\", \"\")\n",
    "                    value = div.text.strip().replace(\". Xem th√¥ng tin h√£ng\", \"\")\n",
    "                    specs[key] = value\n",
    "                    # if key in ALLOWED_KEYS and value:\n",
    "                    #     specs[key] = value\n",
    "        else:\n",
    "            # ‚úÖ Lo·∫°i 2 (l·ªçc theo ALLOWED_KEYS)\n",
    "            boxes = soup.select(\"div.specification-item div.box-specifi ul li\")\n",
    "            for li in boxes:\n",
    "                asides = li.find_all(\"aside\")\n",
    "                if len(asides) >= 2:\n",
    "                    key = asides[0].text.strip().lower().replace(\":\", \"\")\n",
    "                    value = asides[1].text.strip().replace(\". Xem th√¥ng tin h√£ng\", \"\")\n",
    "                    if key in ALLOWED_KEYS and value:\n",
    "                        specs[key] = value\n",
    "\n",
    "        product_details.append({\n",
    "            \"title\": title,\n",
    "            \"url\": url,\n",
    "            \"specs\": specs\n",
    "        })\n",
    "\n",
    "        time.sleep(1)  # tr√°nh b·ªã block\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error crawling {url}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n‚úÖ Crawled details for {len(product_details)} products.\")\n",
    "\n",
    "# ‚úÖ L∆∞u ra CSV (d√πng <br> ƒë·ªÉ ng·∫Øt d√≤ng c√°c specs)\n",
    "with open(\"products_details.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"title\", \"url\", \"specifications\"])\n",
    "    for p in product_details:\n",
    "        specs_str = \"<br>\".join([f\"{k}: {v}\" for k, v in p[\"specs\"].items()])\n",
    "        writer.writerow([p[\"title\"], p[\"url\"], specs_str])\n",
    "\n",
    "print(\"‚úÖ Saved to products_details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd09cf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/131) Crawling details for: OPPO Reno14 F 5G 12GB/256GB\n",
      "(2/131) Crawling details for: Samsung Galaxy Z Flip7 FE 5G 8GB/128GB\n",
      "(3/131) Crawling details for: iPhone 16 Pro Max 256GB\n",
      "(4/131) Crawling details for: iPhone 16 Pro 128GB\n",
      "(5/131) Crawling details for: Samsung Galaxy Z Fold7 5G 12GB/256GB\n",
      "(6/131) Crawling details for: Samsung Galaxy Z Flip7 5G 12GB/256GB\n",
      "(7/131) Crawling details for: OPPO Reno14 5G 12GB/512GB\n",
      "(8/131) Crawling details for: OPPO Reno14 Pro 5G 12GB/512GB\n",
      "(9/131) Crawling details for: Xiaomi Redmi Note 14 Pro 8GB/256GB\n",
      "(10/131) Crawling details for: Xiaomi Redmi Note 14 Pro+ 5G 8GB/256GB\n",
      "(11/131) Crawling details for: vivo Y39 5G 8GB/128GB\n",
      "(12/131) Crawling details for: vivo V50 Lite 5G 8GB/256GB\n",
      "(13/131) Crawling details for: realme 14T 5G 8GB/256GB\n",
      "(14/131) Crawling details for: HONOR 400 5G 12GB/256GB ƒêen\n",
      "(15/131) Crawling details for: Tecno Spark 30 8GB/128GB\n",
      "(16/131) Crawling details for: Masstel S9 6GB/256GB\n",
      "(17/131) Crawling details for: iPhone 16 Plus 128GB\n",
      "(18/131) Crawling details for: iPhone 16 128GB\n",
      "(19/131) Crawling details for: Samsung Galaxy A06 5G 6GB/128GB\n",
      "(20/131) Crawling details for: Samsung Galaxy A36 5G 12GB/256GB\n",
      "(21/131) Crawling details for: OPPO A5x 4GB/64GB\n",
      "(22/131) Crawling details for: OPPO A5 Pro 8GB/256GB\n",
      "(23/131) Crawling details for: Xiaomi Redmi 13x 6GB/128GB\n",
      "(24/131) Crawling details for: vivo Y19s Pro 8GB/128GB\n",
      "(25/131) Crawling details for: vivo Y29 8GB/128GB\n",
      "(26/131) Crawling details for: realme C71 6GB/128GB\n",
      "(27/131) Crawling details for: HONOR 400 Lite 12GB/256GB\n",
      "(28/131) Crawling details for: Samsung Galaxy S25 Ultra 5G 12GB/256GB\n",
      "(29/131) Crawling details for: iPhone 16e 128GB\n",
      "(30/131) Crawling details for: iPhone 15 128GB\n",
      "(31/131) Crawling details for: Samsung Galaxy Z Fold6 5G 12GB/256GB\n",
      "(32/131) Crawling details for: Samsung Galaxy A26 5G 6GB/128GB\n",
      "(33/131) Crawling details for: OPPO Reno13 F 5G 8GB/256GB\n",
      "(34/131) Crawling details for: Xiaomi 15 5G 12GB/512GB\n",
      "(35/131) Crawling details for: OPPO Reno13 5G 12GB/256GB\n",
      "(36/131) Crawling details for: Xiaomi 15 Ultra 5G 16GB/512GB Tr·∫Øng\n",
      "(37/131) Crawling details for: realme 14 5G 12GB/256GB\n",
      "(38/131) Crawling details for: HONOR X8c 8GB/256GB\n",
      "(39/131) Crawling details for: iPhone 15 Plus 128GB\n",
      "(40/131) Crawling details for: iPhone 13 128GB\n",
      "(41/131) Crawling details for: Samsung Galaxy S24 FE 5G 8GB/256GB\n",
      "(42/131) Crawling details for: Samsung Galaxy S24 5G 8GB/256GB\n",
      "(43/131) Crawling details for: OPPO A3x 4GB/64GB\n",
      "(44/131) Crawling details for: Xiaomi 14T 5G 12GB/256GB\n",
      "(45/131) Crawling details for: Xiaomi 14T Pro 5G 12GB/256GB\n",
      "(46/131) Crawling details for: OPPO Find N5 5G 16GB/512GB\n",
      "(47/131) Crawling details for: Tecno Spark GO 1 3GB/64GB\n",
      "(48/131) Crawling details for: realme C75x 8GB/128GB\n",
      "(49/131) Crawling details for: vivo Y19s 6GB/128GB\n",
      "(50/131) Crawling details for: HONOR X9c Smart 5G 12GB/256GB\n",
      "(51/131) Crawling details for: HONOR X6b 6GB/128GB T√≠m\n",
      "(52/131) Crawling details for: iPhone 14 128GB\n",
      "(53/131) Crawling details for: iPhone 15 Pro Max 256GB\n",
      "(54/131) Crawling details for: Samsung Galaxy A56 5G 12GB/256GB\n",
      "(55/131) Crawling details for: Xiaomi Redmi A3 3GB/64GB\n",
      "(56/131) Crawling details for: OPPO A3 8GB/128GB\n",
      "(57/131) Crawling details for: Samsung Galaxy S25 5G 12GB/256GB\n",
      "(58/131) Crawling details for: Xiaomi Redmi 13 6GB/128GB\n",
      "(59/131) Crawling details for: HONOR X8b 8GB/512GB\n",
      "(60/131) Crawling details for: OPPO A60 8GB/128GB\n",
      "(61/131) Crawling details for: Xiaomi Redmi 14C 6GB/128GB\n",
      "(62/131) Crawling details for: realme 13+ 5G 12GB/256GB\n",
      "(63/131) Crawling details for: vivo Y04 4GB/128GB\n",
      "(64/131) Crawling details for: Samsung Galaxy A35 5G 8GB/256GB\n",
      "(65/131) Crawling details for: OPPO Reno12 F 5G 12GB/256GB\n",
      "(66/131) Crawling details for: OPPO Reno13 Pro 5G 12GB/512GB\n",
      "(67/131) Crawling details for: realme C75 8GB/128GB\n",
      "(68/131) Crawling details for: vivo V40 Lite 8GB/256GB\n",
      "(69/131) Crawling details for: OPPO Reno12 5G 12GB/256GB H·ªìng\n",
      "(70/131) Crawling details for: OPPO Find X8 5G 16GB/512GB H·ªìng\n",
      "(71/131) Crawling details for: realme Note 60 6GB/128GB\n",
      "(72/131) Crawling details for: vivo V30 5G 12GB/512GB\n",
      "(73/131) Crawling details for: vivo V30e 5G 12GB/256GB\n",
      "(74/131) Crawling details for: realme Note 60x 4GB/64GB\n",
      "(75/131) Crawling details for: Xiaomi Redmi Note 14 8GB/128GB\n",
      "(76/131) Crawling details for: Samsung Galaxy A06 4GB/64GB\n",
      "(77/131) Crawling details for: Samsung Galaxy A16 5G 8GB/256GB\n",
      "(78/131) Crawling details for: Xiaomi Redmi A5 3GB/64GB\n",
      "(79/131) Crawling details for: Nokia HMD 105 4G\n",
      "(80/131) Crawling details for: OPPO Reno12 F 8GB/256GB\n",
      "(81/131) Crawling details for: OPPO Reno14 F 5G 8GB/256GB H·ªìng\n",
      "(82/131) Crawling details for: Masstel IZI 10 4G\n",
      "(83/131) Crawling details for: Nokia 220 4G\n",
      "(84/131) Crawling details for: Xiaomi Redmi Note 14 Pro 5G 8GB/256GB\n",
      "(85/131) Crawling details for: Masstel IZI T6 4G\n",
      "(86/131) Crawling details for: Viettel Sumo 4G T2\n",
      "(87/131) Crawling details for: Masstel Fami 50 4G\n",
      "(88/131) Crawling details for: Mobell M539 4G\n",
      "(89/131) Crawling details for: Mobell M331 4G\n",
      "(90/131) Crawling details for: Nokia 105 4G Pro\n",
      "(91/131) Crawling details for: Nokia 110 4G Pro\n",
      "(92/131) Crawling details for: Samsung Galaxy S24 Ultra 5G 12GB/256GB\n",
      "(93/131) Crawling details for: Xiaomi Redmi Note 14 5G 8GB/256GB\n",
      "(94/131) Crawling details for: Benco 4G G3\n",
      "(95/131) Crawling details for: HONOR X5b Plus 4GB/128GB\n",
      "(96/131) Crawling details for: Mobell F309 4G\n",
      "(97/131) Crawling details for: Mobell M239 4G\n",
      "(98/131) Crawling details for: vivo V50 Lite 8GB/256GB\n",
      "(99/131) Crawling details for: HONOR X7c 8GB/256GB\n",
      "(100/131) Crawling details for: Samsung Galaxy M35 5G 8GB/256GB\n",
      "(101/131) Crawling details for: HONOR X6c 6GB/128GB\n",
      "(102/131) Crawling details for: Samsung Galaxy S25 Plus 5G 12GB/256GB\n",
      "(103/131) Crawling details for: Nokia 3210 4G\n",
      "(104/131) Crawling details for: vivo Y03 4GB/128GB\n",
      "(105/131) Crawling details for: vivo V40 5G 12GB/256GB\n",
      "(106/131) Crawling details for: Tecno Spark 30C 6GB/128GB\n",
      "(107/131) Crawling details for: realme Note 50 3GB/64GB\n",
      "(108/131) Crawling details for: Mobell F209 4G\n",
      "(109/131) Crawling details for: realme C65s 6GB/128GB\n",
      "(110/131) Crawling details for: Samsung Galaxy S25 Edge 5G 12GB/512GB\n",
      "(111/131) Crawling details for: TCL 406s 4GB/64GB\n",
      "(112/131) Crawling details for: Samsung Galaxy A16 8GB/128GB\n",
      "(113/131) Crawling details for: HONOR 400 Pro 5G 12GB/512GB\n",
      "(114/131) Crawling details for: OPPO A58 8GB/128GB\n",
      "(115/131) Crawling details for: vivo Y18 4GB/128GB\n",
      "(116/131) Crawling details for: vivo Y28 8GB/128GB\n",
      "(117/131) Crawling details for: Masstel Fami 60S 4G\n",
      "(118/131) Crawling details for: TCL 60 NXTPaper 8GB/256GB\n",
      "(119/131) Crawling details for: OPPO Reno12 5G 12GB/512GB\n",
      "(120/131) Crawling details for: realme 12 8GB/256GB\n",
      "(121/131) Crawling details for: OPPO Find N3 Flip 5G 12GB/256GB H·ªìng\n",
      "(122/131) Crawling details for: OPPO Find X8 Pro 5G 16GB/512GB\n",
      "(123/131) Crawling details for: OPPO Reno13 F 8GB/256GB\n",
      "(124/131) Crawling details for: OPPO Reno12 Pro 5G 12GB/512GB\n",
      "(125/131) Crawling details for: Tecno Spark 30 5G 6GB/128GB\n",
      "(126/131) Crawling details for: OPPO Find N3 5G 16GB/512GB\n",
      "(127/131) Crawling details for: Samsung Galaxy A55 5G 8GB/256GB\n",
      "(128/131) Crawling details for: HONOR Magic V3 5G 12GB/512GB\n",
      "(129/131) Crawling details for: Samsung Galaxy M15 5G 6GB/128GB\n",
      "(130/131) Crawling details for: OPPO A5i Pro 8GB/128GB\n",
      "(131/131) Crawling details for: OPPO A5i 4GB/64GB\n",
      "\n",
      "‚úÖ Crawled details for 131 products.\n",
      "‚úÖ Saved to products_details_enhanced.csv\n",
      "\n",
      "üìä TH·ªêNG K√ä:\n",
      "  - trung_cao: 30 s·∫£n ph·∫©m\n",
      "  - unknown: 8 s·∫£n ph·∫©m\n",
      "  - cao: 16 s·∫£n ph·∫©m\n",
      "  - trung: 32 s·∫£n ph·∫©m\n",
      "  - thap: 45 s·∫£n ph·∫©m\n",
      "\n",
      "üîç V√≠ d·ª• d·ªØ li·ªáu:\n",
      "  - T√™n: OPPO Reno14 F 5G 12GB/256GB\n",
      "  - Gi√°: 10.300.000\n",
      "  - M·ª©c gi√°: trung_cao\n",
      "  - T√≠nh nƒÉng: ['RAM l·ªõn']\n",
      "  - Ng∆∞·ªùi d√πng: ['gaming']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# ‚úÖ Chuy·ªÉn h·∫øt v·ªÅ lowercase ƒë·ªÉ so kh·ªõp\n",
    "ALLOWED_KEYS = {\n",
    "    \"c√¥ng ngh·ªá m√†n h√¨nh\",\n",
    "    \"ƒë·ªô ph√¢n gi·∫£i m√†n h√¨nh\",\n",
    "    \"m√†n h√¨nh r·ªông\",\n",
    "    \"h·ªá ƒëi·ªÅu h√†nh\",\n",
    "    \"ƒë·ªô ph√¢n gi·∫£i camera sau\",\n",
    "    \"ƒë·ªô ph√¢n gi·∫£i camera tr∆∞·ªõc\",\n",
    "    \"chip x·ª≠ l√Ω (cpu)\",\n",
    "    \"ram\",\n",
    "    \"dung l∆∞·ª£ng l∆∞u tr·ªØ\",\n",
    "    \"sim\",\n",
    "    \"m·∫°ng di ƒë·ªông\",\n",
    "    \"dung l∆∞·ª£ng pin\",\n",
    "    \"h·ªó tr·ª£ s·∫°c t·ªëi ƒëa\",\n",
    "    \"h√£ng\"\n",
    "}\n",
    "\n",
    "def extract_price(soup):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t gi√° s·∫£n ph·∫©m t·ª´ c√°c ƒë·ªãnh d·∫°ng kh√°c nhau\n",
    "    \"\"\"\n",
    "    price = None\n",
    "    \n",
    "    # Lo·∫°i 1: <div class=\"item cf-left\"> -> <div> -> <b>Gi√° b√°n: <b>10.000.000<b/><b/>\n",
    "    price_items = soup.select(\"div.item.cf-left\")\n",
    "    for item in price_items:\n",
    "        b_tags = item.find_all(\"b\")\n",
    "        for b_tag in b_tags:\n",
    "            text = b_tag.get_text().strip().lower()\n",
    "            if \"gi√° b√°n\" in text or \"gi√°\" in text:\n",
    "                # T√¨m gi√° trong c√°c th·∫ª b ti·∫øp theo\n",
    "                parent = b_tag.parent\n",
    "                if parent:\n",
    "                    price_text = parent.get_text()\n",
    "                    price_match = re.search(r'[\\d,.\\s]+', price_text.replace(\"Gi√° b√°n:\", \"\").strip())\n",
    "                    if price_match:\n",
    "                        price = price_match.group().strip()\n",
    "                        break\n",
    "        if price:\n",
    "            break\n",
    "    \n",
    "    # Lo·∫°i 2 - Ki·ªÉu 1: <div class=\"price-one\"> -> <div class=\"box-price\"> -> <p class=\"box-price-present\">\n",
    "    if not price:\n",
    "        price_one = soup.select_one(\"div.price-one div.box-price p.box-price-present\")\n",
    "        if price_one:\n",
    "            price = price_one.get_text().strip()\n",
    "    \n",
    "    # Lo·∫°i 2 - Ki·ªÉu 2: <div class=\"bs_price\"> -> <strong>1.000.000</strong>\n",
    "    if not price:\n",
    "        bs_price = soup.select_one(\"div.bs_price strong\")\n",
    "        if bs_price:\n",
    "            price = bs_price.get_text().strip()\n",
    "    \n",
    "    # Th√™m c√°c pattern kh√°c c√≥ th·ªÉ c√≥\n",
    "    if not price:\n",
    "        # T√¨m trong c√°c class ph·ªï bi·∫øn kh√°c\n",
    "        common_price_selectors = [\n",
    "            \".price-current\",\n",
    "            \".price-new\",\n",
    "            \".price-main\",\n",
    "            \".product-price\",\n",
    "            \".price-box strong\",\n",
    "            \".price-present\",\n",
    "            \"span.price\",\n",
    "            \".current-price\"\n",
    "        ]\n",
    "        \n",
    "        for selector in common_price_selectors:\n",
    "            price_elem = soup.select_one(selector)\n",
    "            if price_elem:\n",
    "                price = price_elem.get_text().strip()\n",
    "                break\n",
    "    \n",
    "    # L√†m s·∫°ch gi√° (lo·∫°i b·ªè k√Ω t·ª± kh√¥ng c·∫ßn thi·∫øt)\n",
    "    if price:\n",
    "        price = re.sub(r'[^\\d,.\\s‚Ç´]', '', price).strip()\n",
    "        price = price.replace('‚Ç´', '').strip()\n",
    "    \n",
    "    return price\n",
    "\n",
    "def categorize_price(price_str):\n",
    "    \"\"\"\n",
    "    Ph√¢n lo·∫°i m·ª©c gi√° ƒë·ªÉ h·ªó tr·ª£ t∆∞ v·∫•n\n",
    "    \"\"\"\n",
    "    if not price_str:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    # Chuy·ªÉn gi√° v·ªÅ s·ªë (lo·∫°i b·ªè d·∫•u ph·∫©y, ch·∫•m)\n",
    "    price_clean = re.sub(r'[,.\\s]', '', price_str)\n",
    "    try:\n",
    "        price_num = int(price_clean)\n",
    "        if price_num < 5000000:\n",
    "            return \"thap\"  # D∆∞·ªõi 5 tri·ªáu\n",
    "        elif price_num < 10000000:\n",
    "            return \"trung\"  # 5-10 tri·ªáu\n",
    "        elif price_num < 20000000:\n",
    "            return \"trung_cao\"  # 10-20 tri·ªáu\n",
    "        else:\n",
    "            return \"cao\"  # Tr√™n 20 tri·ªáu\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "def extract_key_features(specs):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t c√°c t√≠nh nƒÉng n·ªïi b·∫≠t ƒë·ªÉ h·ªó tr·ª£ t∆∞ v·∫•n\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Camera\n",
    "    if \"ƒë·ªô ph√¢n gi·∫£i camera sau\" in specs:\n",
    "        camera_value = specs[\"ƒë·ªô ph√¢n gi·∫£i camera sau\"]\n",
    "        if \"50\" in camera_value or \"48\" in camera_value:\n",
    "            features.append(\"camera ch·∫•t l∆∞·ª£ng cao\")\n",
    "    \n",
    "    # Pin\n",
    "    if \"dung l∆∞·ª£ng pin\" in specs:\n",
    "        battery_value = specs[\"dung l∆∞·ª£ng pin\"]\n",
    "        battery_match = re.search(r'(\\d+)', battery_value)\n",
    "        if battery_match:\n",
    "            battery_mah = int(battery_match.group(1))\n",
    "            if battery_mah >= 5000:\n",
    "                features.append(\"pin kh·ªßng\")\n",
    "    \n",
    "    # RAM\n",
    "    if \"ram\" in specs:\n",
    "        ram_value = specs[\"ram\"]\n",
    "        if \"12\" in ram_value or \"16\" in ram_value:\n",
    "            features.append(\"RAM l·ªõn\")\n",
    "    \n",
    "    # S·∫°c nhanh\n",
    "    if \"h·ªó tr·ª£ s·∫°c t·ªëi ƒëa\" in specs:\n",
    "        charging_value = specs[\"h·ªó tr·ª£ s·∫°c t·ªëi ƒëa\"]\n",
    "        charging_match = re.search(r'(\\d+)', charging_value)\n",
    "        if charging_match:\n",
    "            charging_w = int(charging_match.group(1))\n",
    "            if charging_w >= 60:\n",
    "                features.append(\"s·∫°c si√™u nhanh\")\n",
    "    \n",
    "    return features\n",
    "\n",
    "product_details = []\n",
    "\n",
    "for i, link in enumerate(unique_links, 1):\n",
    "    url = link[\"href\"]\n",
    "    title = link[\"title\"]\n",
    "    print(f\"({i}/{len(unique_links)}) Crawling details for: {title}\")\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, timeout=10)\n",
    "        r.encoding = \"utf-8\"  # ‚úÖ S·ª≠a l·ªói encoding\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "        specs = {}\n",
    "        \n",
    "        # ‚úÖ Tr√≠ch xu·∫•t gi√° s·∫£n ph·∫©m\n",
    "        price = extract_price(soup)\n",
    "        price_category = categorize_price(price)\n",
    "\n",
    "        # ‚úÖ Lo·∫°i 1 (ch·ªâ l∆∞u l·∫°i c√°c key ƒë∆∞·ª£c ph√©p)\n",
    "        items = soup.select(\"div.item.cf-right ul.parameter li\")\n",
    "        if items:\n",
    "            for li in items:\n",
    "                span = li.find(\"span\")\n",
    "                div = li.find(\"div\")\n",
    "                if span and div:\n",
    "                    key = span.text.strip().lower().replace(\":\", \"\")\n",
    "                    value = div.text.strip().replace(\". Xem th√¥ng tin h√£ng\", \"\")\n",
    "                    specs[key] = value\n",
    "        else:\n",
    "            # ‚úÖ Lo·∫°i 2 (l·ªçc theo ALLOWED_KEYS)\n",
    "            boxes = soup.select(\"div.specification-item div.box-specifi ul li\")\n",
    "            for li in boxes:\n",
    "                asides = li.find_all(\"aside\")\n",
    "                if len(asides) >= 2:\n",
    "                    key = asides[0].text.strip().lower().replace(\":\", \"\")\n",
    "                    value = asides[1].text.strip().replace(\". Xem th√¥ng tin h√£ng\", \"\")\n",
    "                    if key in ALLOWED_KEYS and value:\n",
    "                        specs[key] = value\n",
    "\n",
    "        # ‚úÖ Tr√≠ch xu·∫•t t√≠nh nƒÉng n·ªïi b·∫≠t\n",
    "        key_features = extract_key_features(specs)\n",
    "        \n",
    "        # ‚úÖ X√°c ƒë·ªãnh nh√≥m ng∆∞·ªùi d√πng m·ª•c ti√™u\n",
    "        target_users = []\n",
    "        if \"camera ch·∫•t l∆∞·ª£ng cao\" in key_features:\n",
    "            target_users.append(\"ch·ª•p ·∫£nh\")\n",
    "        if \"RAM l·ªõn\" in key_features:\n",
    "            target_users.append(\"gaming\")\n",
    "        if \"pin kh·ªßng\" in key_features:\n",
    "            target_users.append(\"s·ª≠ d·ª•ng l√¢u\")\n",
    "        if not target_users:\n",
    "            target_users.append(\"s·ª≠ d·ª•ng c∆° b·∫£n\")\n",
    "\n",
    "        product_details.append({\n",
    "            \"title\": title,\n",
    "            \"url\": url,\n",
    "            \"price\": price or \"Li√™n h·ªá\",\n",
    "            \"price_category\": price_category,\n",
    "            \"key_features\": key_features,\n",
    "            \"target_users\": target_users,\n",
    "            \"specs\": specs\n",
    "        })\n",
    "\n",
    "        time.sleep(1)  # tr√°nh b·ªã block\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error crawling {url}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n‚úÖ Crawled details for {len(product_details)} products.\")\n",
    "\n",
    "# ‚úÖ L∆∞u ra CSV v·ªõi th√¥ng tin m·ªü r·ªông\n",
    "with open(\"products_details_enhanced.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"title\", \"url\", \"price\", \"price_category\", \"key_features\", \"target_users\", \"specifications\"])\n",
    "    for p in product_details:\n",
    "        specs_str = \"<br>\".join([f\"{k}: {v}\" for k, v in p[\"specs\"].items()])\n",
    "        key_features_str = \", \".join(p[\"key_features\"])\n",
    "        target_users_str = \", \".join(p[\"target_users\"])\n",
    "        writer.writerow([\n",
    "            p[\"title\"], \n",
    "            p[\"url\"], \n",
    "            p[\"price\"], \n",
    "            p[\"price_category\"],\n",
    "            key_features_str,\n",
    "            target_users_str,\n",
    "            specs_str\n",
    "        ])\n",
    "\n",
    "print(\"‚úÖ Saved to products_details_enhanced.csv\")\n",
    "\n",
    "# ‚úÖ Th·ªëng k√™ nhanh\n",
    "print(\"\\nüìä TH·ªêNG K√ä:\")\n",
    "price_stats = {}\n",
    "for p in product_details:\n",
    "    category = p[\"price_category\"]\n",
    "    price_stats[category] = price_stats.get(category, 0) + 1\n",
    "\n",
    "for category, count in price_stats.items():\n",
    "    print(f\"  - {category}: {count} s·∫£n ph·∫©m\")\n",
    "\n",
    "print(f\"\\nüîç V√≠ d·ª• d·ªØ li·ªáu:\")\n",
    "if product_details:\n",
    "    sample = product_details[0]\n",
    "    print(f\"  - T√™n: {sample['title']}\")\n",
    "    print(f\"  - Gi√°: {sample['price']}\")\n",
    "    print(f\"  - M·ª©c gi√°: {sample['price_category']}\")\n",
    "    print(f\"  - T√≠nh nƒÉng: {sample['key_features']}\")\n",
    "    print(f\"  - Ng∆∞·ªùi d√πng: {sample['target_users']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
